{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVL7_bgmIAPR"
   },
   "source": [
    "# Unsupervised Learning: Clustering Lab\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6ZbYjZZZ_yLV"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin, ClusterMixin\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from scipy.io import arff\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools as it\n",
    "from typing import List, Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTlK-kijk8Mg",
    "tags": []
   },
   "source": [
    "## 4. (Optional 5% extra credit) For your silhouette experiment above, write and use your own code to calculate the silhouette scores, rather than the SK or other version. \n",
    "\n",
    "Doing this here as it is used in the other classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silhouette(*, classes, data=None, dist_matrix=None):\n",
    "    \"\"\"\n",
    "    Calulate silhouette score.\n",
    "    Args:\n",
    "        classes (array-like): 1-D array specifying the classes of `data`\n",
    "        data (array-like): 2-D array specifying the data. \n",
    "                            If dist_matrix is not None, then `data` is ignored.\n",
    "        dist_matrix (array-like): 2-D array specifying the distance between each point in `data`.\n",
    "                            Does not need to be passed if `data` is passed.\n",
    "    \"\"\"\n",
    "    if dist_matrix is None:\n",
    "        dist_matrix = np.linalg.norm(data[:,None,:] - data[None,:,:], axis=-1)\n",
    "    # Calculate average distance matrix\n",
    "    np.fill_diagonal(dist_matrix, np.nan)\n",
    "    avg_dist_matrix = np.array([np.nanmean(dist_matrix[classes==i], axis= 0) for i in np.unique(classes)]).T\n",
    "    intra_dists = avg_dist_matrix[range(len(classes)), classes]\n",
    "    avg_dist_matrix[range(len(classes)), classes] = np.inf\n",
    "    nearest_dists = np.min(avg_dist_matrix, axis=1)\n",
    "    point_scores = (nearest_dists - intra_dists) / np.maximum(nearest_dists, intra_dists)\n",
    "    point_scores[np.isnan(point_scores)] = 0\n",
    "    return np.average(point_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCcEPx5VIORj",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 1. (50%) Implement the k-means clustering algorithm and the HAC (Hierarchical Agglomerative Clustering) algorithm.\n",
    "\n",
    "### 1.1.1 HAC\n",
    "\n",
    "### Code requirements \n",
    "- ~~HAC should support both single link and complete link options.~~\n",
    "- HAC automatically generates all clusterings from n to 1.  To simplify the amount of output you may want to implement a mechanism to specify for which k values actual output will be generated.\n",
    "\n",
    "\n",
    "---\n",
    "The output should include the following:\n",
    "- ~~The number of clusters (k).~~\n",
    "- ~~The silhouette score of the full clustering. (You can either write and use your own silhouette_score function (extra credit) or use sklearn's)~~\n",
    "\n",
    "\n",
    "For each cluster report include:\n",
    "\n",
    "\n",
    "- ~~The centroid id.~~\n",
    "- ~~The number of instances tied to that centroid.~~\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_a2KSZ_7AN0G"
   },
   "outputs": [],
   "source": [
    "class HACClustering(BaseEstimator,ClusterMixin):\n",
    "\n",
    "    def __init__(self,k=3,link_type='single'): ## add parameters here\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            k = how many final clusters to have\n",
    "            link_type = single or complete. when combining two clusters use complete link or single link\n",
    "        \"\"\"\n",
    "        self.link_type = link_type\n",
    "        self.k = k\n",
    "        self.clusters: List[List[np.array]] = []\n",
    "        self.silhouette=0\n",
    "        \n",
    "    def fit(self, X, y=None, *, normalize=True):\n",
    "        \"\"\" Fit the data; In this lab this will make the K clusters :D\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data\n",
    "            y (array-like): An optional argument. Clustering is usually unsupervised so you don't need labels\n",
    "        Returns:\n",
    "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
    "        \"\"\"\n",
    "        if normalize:\n",
    "            X = (X - np.min(X, axis=0))/(np.max(X, axis=0) - np.min(X, axis=0))\n",
    "            \n",
    "        link_func = np.min if self.link_type == \"single\" else np.max\n",
    "        used = np.inf if self.link_type == \"single\" else -np.inf\n",
    "        \n",
    "        dist_matrix = np.linalg.norm(X[None,:,:] - X[:,None,:], axis=-1)\n",
    "        dist_matrix[dist_matrix==0] = used\n",
    "        cluster_by_idx = [[i] for i in range(len(X))]\n",
    "        \n",
    "        for _ in range(len(X) - self.k):\n",
    "            # Find distance between every combination of clusters\n",
    "            cluster_dists = np.full((len(cluster_by_idx), len(cluster_by_idx)), np.inf)\n",
    "            for i, cluster1 in enumerate(cluster_by_idx):\n",
    "                for j, cluster2 in enumerate(cluster_by_idx[i+1:]):\n",
    "                    j += i+1 #Makes sure indexes match up. Looped this way to not loop when i == j or i > j (duplicate distance)\n",
    "                    relevant_dists = dist_matrix[cluster1,:][:, cluster2]\n",
    "                    cluster_dists[i, j] = link_func(relevant_dists)\n",
    "            # Find closest clusters\n",
    "            c1_idx, c2_idx = np.unravel_index(np.argmin(cluster_dists), cluster_dists.shape)\n",
    "            # Merge clusters\n",
    "            cluster_by_idx[c1_idx] += cluster_by_idx.pop(c2_idx)\n",
    "            \n",
    "        labels = []\n",
    "        for point in range(len(X)):\n",
    "            for i, cluster in enumerate(cluster_by_idx):\n",
    "                if point in cluster:\n",
    "                    labels.append(i)\n",
    "                    break\n",
    "        self.silhouette = silhouette(data=X, classes=labels)\n",
    "                    \n",
    "                \n",
    "        self.clusters = [np.array([X[idx] for idx in cluster]) for cluster in cluster_by_idx]\n",
    "        return self\n",
    "    \n",
    "    def print_clusters(self):\n",
    "        \"\"\"\n",
    "            Used for grading.\n",
    "            print(\"Num clusters: {:d}\\n\".format(k))\n",
    "            print(\"Silhouette score: {:.4f}\\n\\n\".format(silhouette_score))\n",
    "            for each cluster and centroid:\n",
    "                print(np.array2string(centroid,precision=4,separator=\",\"))\n",
    "                print(\"{:d}\\n\".format(size of cluster))\n",
    "        \"\"\"\n",
    "        print(f\"Num clusters: {len(self.clusters)}\")\n",
    "        print(f\"Silhouette score: {self.silhouette}\")\n",
    "        for cluster in self.clusters:\n",
    "            print(np.array2string(np.average(cluster, axis=0),precision=4,separator=\",\"))\n",
    "            print(\"{:d}\\n\".format(len(cluster)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KibCIXIThpbE"
   },
   "source": [
    "### 1.1.2 Debug \n",
    "\n",
    "Debug your model by running it on the [Debug Abalone Dataset](https://byu.instructure.com/courses/14142/files?preview=4735805)\n",
    "\n",
    "\n",
    "---\n",
    "The dataset was modified to be a lot smaller. The last datapoint should be on line 359 or the point 0.585,0.46,0.185,0.922,0.3635,0.213,0.285,10. The remaining points should be commented out.\n",
    "\n",
    "\n",
    "- Make sure to include the output class (last column) as an additional input feature\n",
    "- Normalize Data\n",
    "- K = 5\n",
    "- Use 4 decimal places and DO NOT ROUND when reporting silhouette score and centroid values.\n",
    "\n",
    "\n",
    "---\n",
    "Solutions in files:\n",
    "\n",
    "[Debug HAC Single (Silhouette).txt](https://byu.instructure.com/courses/14142/files?preview=4735819)\n",
    "\n",
    "[Debug HAC Complete (Silhouette).txt](https://byu.instructure.com/courses/14142/files?preview=4735820)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(path, *, split=True, x_type=float, y_type=str):\n",
    "    data, meta = arff.loadarff(path)\n",
    "    data = np.array([[*row] for row in data])\n",
    "    if split:\n",
    "        X, y = data[:,:-1].astype(x_type), data[:,-1].astype(y_type)\n",
    "    else:\n",
    "        X, y = data.astype(x_type), None\n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num clusters: 5\n",
      "Silhouette score: 0.34525948566983433\n",
      "[0.599 ,0.5923,0.4915,0.2826,0.2682,0.2921,0.2316,0.3849]\n",
      "195\n",
      "\n",
      "[0.9189,0.9438,0.7105,0.7016,0.759 ,0.7222,0.4472,0.8824]\n",
      "1\n",
      "\n",
      "[1.    ,0.9831,0.8026,0.8343,0.6575,0.7825,0.9221,0.8824]\n",
      "2\n",
      "\n",
      "[1.    ,0.9888,0.7895,1.    ,1.    ,0.8915,0.7186,0.5882]\n",
      "1\n",
      "\n",
      "[0.9189,0.9888,0.8684,0.719 ,0.5797,0.7512,0.6432,0.9412]\n",
      "1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74162/843845863.py:15: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist_matrix = np.array([np.nanmean(dist_matrix[classes==i], axis= 0) for i in np.unique(classes)]).T\n"
     ]
    }
   ],
   "source": [
    "# Debug Here\n",
    "X, y = load_data(\"data/abalone.arff\", split=False)\n",
    "\n",
    "hac = HACClustering(5, \"single\")\n",
    "hac.fit(X)\n",
    "hac.print_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kY3VNB1ui03N"
   },
   "source": [
    "### 1.1.3 Evaluation\n",
    "\n",
    "We will evaluate your model based on its print_clusters() output using [Evaluation Seismic-bumps_train Dataset](https://byu.instructure.com/courses/14142/files?preview=4735829)\n",
    "\n",
    "- Make sure to include the output class (last column) as an additional input feature\n",
    "- Normalize Data\n",
    "- K = 5\n",
    "- Use 4 decimal places and DO NOT ROUND when reporting silhouette score and centroid values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3.1 Complete Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2yAxA78QjDh2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num clusters: 5\n",
      "Silhouette score: -0.12186295921454993\n",
      "[0.5173,0.5639,0.5388,0.528 ,0.519 ,0.3946,0.5163]\n",
      "136\n",
      "\n",
      "[0.2774,0.2597,1.    ,0.1224,0.4505,0.7549,0.129 ]\n",
      "1\n",
      "\n",
      "[0.3065,0.3333,0.6979,0.2792,0.3787,1.    ,0.2373]\n",
      "1\n",
      "\n",
      "[0.0884,0.1818,0.    ,0.145 ,0.1538,0.1245,0.    ]\n",
      "1\n",
      "\n",
      "[0.795 ,0.8615,0.4172,0.7654,0.7498,0.9995,0.7553]\n",
      "1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74162/843845863.py:15: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist_matrix = np.array([np.nanmean(dist_matrix[classes==i], axis= 0) for i in np.unique(classes)]).T\n"
     ]
    }
   ],
   "source": [
    "# Load evaluation data\n",
    "X, y = load_data(\"data/seismic-bumps_train.arff\")\n",
    "# Train on evaluation data using complete link\n",
    "hac = HACClustering(k=5, link_type='single')\n",
    "hac.fit(X)\n",
    "# Print clusters\n",
    "hac.print_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3.1 Single Link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2yAxA78QjDh2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num clusters: 5\n",
      "Silhouette score: -0.12186295921454993\n",
      "[0.5173,0.5639,0.5388,0.528 ,0.519 ,0.3946,0.5163]\n",
      "136\n",
      "\n",
      "[0.2774,0.2597,1.    ,0.1224,0.4505,0.7549,0.129 ]\n",
      "1\n",
      "\n",
      "[0.3065,0.3333,0.6979,0.2792,0.3787,1.    ,0.2373]\n",
      "1\n",
      "\n",
      "[0.0884,0.1818,0.    ,0.145 ,0.1538,0.1245,0.    ]\n",
      "1\n",
      "\n",
      "[0.795 ,0.8615,0.4172,0.7654,0.7498,0.9995,0.7553]\n",
      "1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74162/843845863.py:15: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist_matrix = np.array([np.nanmean(dist_matrix[classes==i], axis= 0) for i in np.unique(classes)]).T\n"
     ]
    }
   ],
   "source": [
    "# Load evaluation data\n",
    "X, y = load_data(\"data/seismic-bumps_train.arff\")\n",
    "# Train on evaluation data using complete link\n",
    "hac = HACClustering(k=5, link_type='single')\n",
    "hac.fit(X)\n",
    "# Print clusters\n",
    "hac.print_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 1.2.1 K-Means\n",
    "\n",
    "### Code requirements \n",
    "- Ability to choose k and specify k initial centroids\n",
    "- Use Euclidean Distance as metric\n",
    "- Ability to handle distance ties\n",
    "- Include output label as a cluster feature\n",
    "\n",
    "\n",
    "---\n",
    "The output should include the following:\n",
    "- The number of clusters (k).\n",
    "- The silhouette score of the full clustering. (You can either write and use your own silhouette_score function (extra credit) or use sklearn's)\n",
    "\n",
    "\n",
    "For each cluster report include:\n",
    "\n",
    "\n",
    "- The centroid id.\n",
    "- The number of instances tied to that centroid. \n",
    "---\n",
    "You only need to handle continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "_a2KSZ_7AN0G"
   },
   "outputs": [],
   "source": [
    "class KMEANSClustering(BaseEstimator,ClusterMixin):\n",
    "\n",
    "    def __init__(self,k=3,debug=False, normalize=True): ## add parameters here\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            k = how many final clusters to have\n",
    "            debug = if debug is true use the first k instances as the initial centroids otherwise choose random points as the initial centroids.\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.debug = debug\n",
    "        self.normalize = normalize\n",
    "        self.centroids = None\n",
    "        self.centroid_sizes = None\n",
    "        self.silhouette = 0\n",
    "        \n",
    "        self.X = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\" Fit the data; In this lab this will make the K clusters :D\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data\n",
    "            y (array-like): An optional argument. Clustering is usually unsupervised so you don't need classes\n",
    "        Returns:\n",
    "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        if self.normalize:\n",
    "            X = (X - np.min(X, axis=0))/(np.max(X, axis=0) - np.min(X, axis=0))\n",
    "        centroids = X[np.random.choice(range(len(X)), self.k)] if not self.debug else X[:self.k].copy()\n",
    "        centroid_sizes = np.zeros((self.k,)).astype(int)\n",
    "        prev_centroids = np.full_like(centroids, np.nan)\n",
    "        \n",
    "        c = 0\n",
    "        while np.any(centroids != prev_centroids):\n",
    "            prev_centroids = centroids.copy()\n",
    "            centroid_dists = np.linalg.norm(centroids[:,None,:] - X[None,:,:], axis=-1).T\n",
    "            classes = np.argmin(centroid_dists, axis=1)\n",
    "            for i in range(len(centroids)):\n",
    "                if np.any(classes==i):\n",
    "                    centroids[i] = np.average(X[classes==i], axis=0)\n",
    "                centroid_sizes[i] = np.sum(classes==i)\n",
    "            c+=1\n",
    "                \n",
    "        # Calculate silhouette score\n",
    "        self.silhouette = silhouette(data=X, classes=classes)\n",
    "               \n",
    "        self.centroids = centroids\n",
    "        self.centroid_sizes = centroid_sizes\n",
    "        return self\n",
    "    \n",
    "    def print_clusters(self):\n",
    "        \"\"\"\n",
    "            Used for grading.\n",
    "            print(\"Num clusters: {:d}\\n\".format(k))\n",
    "            print(\"Silhouette score: {:.4f}\\n\\n\".format(silhouette_score))\n",
    "            for each cluster and centroid:\n",
    "                print(np.array2string(centroid,precision=4,separator=\",\"))\n",
    "                print(\"{:d}\\n\".format(size of cluster))\n",
    "        \"\"\"\n",
    "        print(\"Num clusters: {:d}\".format(self.k))\n",
    "        print(\"Silhouette score: {:.4f}\\n\".format(self.silhouette))\n",
    "        dist_matrix = np.sum((self.centroids[:, None, :] - self.X[None, :, :])**2, axis=2)**.5\n",
    "        classes = np.argmin(dist_matrix, axis=0)\n",
    "        for i, (centroid, size) in enumerate(zip(self.centroids, self.centroid_sizes)):\n",
    "            print(np.array2string(centroid,precision=4,separator=\",\"))\n",
    "            print(\"{:d}\\n\".format(size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KibCIXIThpbE",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### 1.2.2 Debug \n",
    "\n",
    "Debug your model by running it on the [Debug Abalone Dataset](https://byu.instructure.com/courses/14142/files?preview=4735805)\n",
    "\n",
    "\n",
    "- Train until convergence\n",
    "- Make sure to include the output class (last column) as an additional input feature\n",
    "- Normalize Data\n",
    "- K = 5\n",
    "- Use the first k instances as the initial centroids\n",
    "- Use 4 decimal places and DO NOT ROUND when reporting silhouette score and centroid values\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "Solutions in files:\n",
    "\n",
    "[Debug K Means (Silhouette).txt](https://byu.instructure.com/courses/14142/files?preview=4735840)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "KgAyy82gixIF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num clusters: 5\n",
      "Silhouette score: 0.3845\n",
      "\n",
      "[0.7325,0.7327,0.627 ,0.3817,0.3633,0.4045,0.3046,0.4839]\n",
      "75\n",
      "\n",
      "[0.3704,0.3519,0.2686,0.0926,0.0935,0.094 ,0.0792,0.218 ]\n",
      "34\n",
      "\n",
      "[0.9035,0.905 ,0.7774,0.6579,0.5767,0.6193,0.5893,0.7279]\n",
      "24\n",
      "\n",
      "[0.5692,0.5628,0.4376,0.211 ,0.2113,0.2248,0.1659,0.317 ]\n",
      "54\n",
      "\n",
      "[0.1296,0.1037,0.1053,0.0177,0.0211,0.0272,0.0135,0.0724]\n",
      "13\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load debug data\n",
    "X, y = load_data(\"data/abalone.arff\", split=False)\n",
    "X\n",
    "\n",
    "# Train on debug data\n",
    "kmns = KMEANSClustering(k=5, debug=True)\n",
    "kmns.fit(X)\n",
    "kmns.print_clusters()\n",
    "\n",
    "# Print clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kY3VNB1ui03N",
    "tags": []
   },
   "source": [
    "### 1.2.3 Evaluation\n",
    "\n",
    "We will evaluate your model based on its print_clusters() output using [Evaluation Seismic-bumps_train Dataset](https://byu.instructure.com/courses/14142/files?preview=4735829)\n",
    "- Train until convergence\n",
    "- Make sure to include the output class (last column) as an additional input feature\n",
    "- Normalize Data\n",
    "- K = 5\n",
    "- Use the first k instances as the initial centroids\n",
    "- Use 4 decimal places and DO NOT ROUND when reporting silhouette score and centroid values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "2yAxA78QjDh2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num clusters: 5\n",
      "Silhouette score: 0.2587\n",
      "\n",
      "[0.5309,0.6006,0.439 ,0.5735,0.5103,0.5342,0.6215]\n",
      "25\n",
      "\n",
      "[0.3461,0.4113,0.4303,0.4128,0.3384,0.2791,0.3367]\n",
      "27\n",
      "\n",
      "[0.3908,0.4086,0.7787,0.319 ,0.4958,0.3748,0.2679]\n",
      "19\n",
      "\n",
      "[0.1698,0.2172,0.4256,0.2178,0.1689,0.318 ,0.172 ]\n",
      "21\n",
      "\n",
      "[0.7961,0.831 ,0.6054,0.7709,0.7802,0.4553,0.7919]\n",
      "48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load evaluation data\n",
    "X, y = load_data(\"data/seismic-bumps_train.arff\")\n",
    "\n",
    "# Train on evaluation data\n",
    "kmns = KMEANSClustering(k=5, debug=True)\n",
    "kmns.fit(X)\n",
    "\n",
    "# Print clusters\n",
    "kmns.print_clusters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vWiTdlbR2Xh",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.1.1 (7.5%) Clustering the Iris Classification problem - HAC\n",
    "\n",
    "Load the Iris Dataset [Iris Dataset](https://byu.instructure.com/courses/14142/files?preview=4421369)\n",
    "\n",
    "- Use single-link and complete link clustering algorithms\n",
    "- State whether you normalize your data or not (your choice).  \n",
    "- Show your results for clusterings using k = 2-7.  \n",
    "- Graph the silhouette score for each k and discuss your results (i.e. what kind of clusters are being made).\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4SSoasDQSKXb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num clusters: 2\n",
      "Silhouette score: 0.6294675561906643\n",
      "[0.1961,0.5908,0.0786,0.06  ]\n",
      "50\n",
      "\n",
      "[0.545 ,0.3633,0.662 ,0.6567]\n",
      "100\n",
      "\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74162/843845863.py:15: RuntimeWarning: Mean of empty slice\n",
      "  avg_dist_matrix = np.array([np.nanmean(dist_matrix[classes==i], axis= 0) for i in np.unique(classes)]).T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num clusters: 3\n",
      "Silhouette score: 0.530889323901593\n",
      "[0.199 ,0.6003,0.0792,0.0595]\n",
      "49\n",
      "\n",
      "[0.0556,0.125 ,0.0508,0.0833]\n",
      "1\n",
      "\n",
      "[0.545 ,0.3633,0.662 ,0.6567]\n",
      "100\n",
      "\n",
      "----------------------------------------\n",
      "Num clusters: 4\n",
      "Silhouette score: 0.3882664409102069\n",
      "[0.199 ,0.6003,0.0792,0.0595]\n",
      "49\n",
      "\n",
      "[0.0556,0.125 ,0.0508,0.0833]\n",
      "1\n",
      "\n",
      "[0.5363,0.3554,0.6563,0.6531]\n",
      "98\n",
      "\n",
      "[0.9722,0.75  ,0.9407,0.8333]\n",
      "2\n",
      "\n",
      "----------------------------------------\n",
      "Num clusters: 5\n",
      "Silhouette score: 0.20510173993234454\n",
      "[0.199 ,0.6003,0.0792,0.0595]\n",
      "49\n",
      "\n",
      "[0.0556,0.125 ,0.0508,0.0833]\n",
      "1\n",
      "\n",
      "[0.5401,0.357 ,0.657 ,0.6529]\n",
      "97\n",
      "\n",
      "[0.1667,0.2083,0.5932,0.6667]\n",
      "1\n",
      "\n",
      "[0.9722,0.75  ,0.9407,0.8333]\n",
      "2\n",
      "\n",
      "----------------------------------------\n",
      "Num clusters: 6\n",
      "Silhouette score: 0.16046278106948017\n",
      "[0.199 ,0.6003,0.0792,0.0595]\n",
      "49\n",
      "\n",
      "[0.0556,0.125 ,0.0508,0.0833]\n",
      "1\n",
      "\n",
      "[0.5373,0.3537,0.6548,0.6493]\n",
      "96\n",
      "\n",
      "[0.1667,0.2083,0.5932,0.6667]\n",
      "1\n",
      "\n",
      "[0.8056,0.6667,0.8644,1.    ]\n",
      "1\n",
      "\n",
      "[0.9722,0.75  ,0.9407,0.8333]\n",
      "2\n",
      "\n",
      "----------------------------------------\n",
      "Num clusters: 7\n",
      "Silhouette score: 0.10936566430229182\n",
      "[0.199 ,0.6003,0.0792,0.0595]\n",
      "49\n",
      "\n",
      "[0.0556,0.125 ,0.0508,0.0833]\n",
      "1\n",
      "\n",
      "[0.5386,0.3539,0.6544,0.6461]\n",
      "95\n",
      "\n",
      "[0.1667,0.2083,0.5932,0.6667]\n",
      "1\n",
      "\n",
      "[0.8056,0.6667,0.8644,1.    ]\n",
      "1\n",
      "\n",
      "[0.4167,0.3333,0.6949,0.9583]\n",
      "1\n",
      "\n",
      "[0.9722,0.75  ,0.9407,0.8333]\n",
      "2\n",
      "\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Iris Classification using single-link\n",
    "# Load evaluation data\n",
    "iris, y = load_data(\"data/iris.arff\", y_type=str)\n",
    "# print(X.shape)\n",
    "# print(y.shape)\n",
    "# Train on evaluation data using complete link\n",
    "scores = []\n",
    "for k in range(2,8):\n",
    "    hac = HACClustering(k=k, link_type='single')\n",
    "    hac.fit(iris)\n",
    "    # Print clusters\n",
    "    hac.print_clusters()\n",
    "    scores.append(hac.silhouette)\n",
    "    print('-'*40)\n",
    "    \n",
    "plt.plot(range(2,8), scores)\n",
    "plt.title(\"Single link\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "plt.ylim(ymin=0, ymax=1.1)\n",
    "plt.title(\"Single-link\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SSoasDQSKXb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num clusters: 2\n",
      "Silhouette score: 0.30391309058110383\n",
      "[0.3436,0.4318,0.367 ,0.3452]\n",
      "116\n",
      "\n",
      "[0.719 ,0.4645,0.8106,0.8419]\n",
      "34\n",
      "\n",
      "----------------------------------------\n",
      "Num clusters: 3\n",
      "Silhouette score: 0.5030674466509139\n",
      "[0.1961,0.5908,0.0786,0.06  ]\n",
      "50\n",
      "\n",
      "[0.4554,0.3112,0.5855,0.5612]\n",
      "66\n",
      "\n",
      "[0.719 ,0.4645,0.8106,0.8419]\n",
      "34\n",
      "\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Iris Classification using single-link\n",
    "scores = []\n",
    "for k in range(2,8):\n",
    "    hac = HACClustering(k=k, link_type='complete')\n",
    "    hac.fit(iris)\n",
    "    # Print clusters\n",
    "    hac.print_clusters()\n",
    "    scores.append(hac.silhouette)\n",
    "    print('-'*40)\n",
    "    \n",
    "plt.plot(range(2,8), scores)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "plt.ylim(ymin=0, ymax=1.1)\n",
    "plt.title(\"Complete-link\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discuss differences between single-link and complete-link**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sum up in one sentence, the single link had a higher silhouette score for the best-case scenario, but the complete-link was more consistent. <br>\n",
    "<br>\n",
    "It seems like the single-link clearly favored a lower `k`, as it had a pretty good silhouette score for `k=2` (.62) and `k=3` (.57). However, after that it dipped very low. On the other hand, the silhouette score for the complete link peaked at `k=3` (.51), but always stayed within the range of about .3 to .51. I think that this is because the single link can classfy better between two or three groups, as the few groups are more distinct and the clustering is not as impeded by a variety of options. On the other hand, the complete link performed about as well for everything since it based its decision-- in a very loose, non-exact sense-- on the more extreme elements of the group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.1.2 (5%) Clustering the Iris Classification problem - HAC\n",
    "\n",
    "Requirements:\n",
    "- Repeat excercise 2.1.1 and include the output label as one of the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X, y = load_data(\"data/iris.arff\", y_type=str)\n",
    "labels = y.copy()\n",
    "y = np.array([(y == val).astype(int) for val in np.unique(y)]).T\n",
    "iris_w_output = np.append(X, y, axis=1)\n",
    "iris_w_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SSoasDQSKXb"
   },
   "outputs": [],
   "source": [
    "# Clustering labels with single-link\n",
    "# Load evaluation data\n",
    "scores = []\n",
    "for k in range(2,8):\n",
    "    hac = HACClustering(k=k, link_type='single')\n",
    "    hac.fit(iris_w_output)\n",
    "    # Print clusters\n",
    "    hac.print_clusters()\n",
    "    scores.append(hac.silhouette)\n",
    "    print('-'*40)\n",
    "    \n",
    "plt.plot(range(2,8), scores)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "plt.ylim(ymin=0, ymax=1.1)\n",
    "plt.title(\"Single-link with output\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SSoasDQSKXb"
   },
   "outputs": [],
   "source": [
    "# Clustering labels with complete-link\n",
    "# Load evaluation data\n",
    "scores = []\n",
    "for k in range(2,8):\n",
    "    hac = HACClustering(k=k, link_type='complete')\n",
    "    hac.fit(iris_w_output)\n",
    "    # Print clusters\n",
    "    hac.print_clusters()\n",
    "    scores.append(hac.silhouette)\n",
    "    print('-'*40)\n",
    "    \n",
    "plt.plot(range(2,8), scores)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "plt.ylim(ymin=0, ymax=1.1)\n",
    "plt.title(\"Complete-link with output\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discuss any differences between the results from 2.1.1 and 2.1.2.**<br>\n",
    "When running the data with the output labels, it drastically improved the scores. In addition, both single link and complete link scored very similarly for all values of `k`. My guess is because including the output labels added a whole new dimension (or three due to one-hot encoding) that helped drastically separate out the data. This is supported by the fact that the optimal value for `k` for both single and complete link was 3, which was the original number of classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vWiTdlbR2Xh",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.2.1 (7.5%) Clustering the Iris Classification problem: K-Means\n",
    "\n",
    "Load the Iris Dataset [Iris Dataset](https://byu.instructure.com/courses/14142/files?preview=4421369)\n",
    "\n",
    "Run K-Means on the Iris dataset using the output label as a feature and without using the output label as a feature\n",
    "\n",
    "Requirements:\n",
    "- State whether you normalize your data or not (your choice).  \n",
    "- Show your results for clusterings using k = 2-7.  \n",
    "- Graph the silhouette score for each k and discuss your results (i.e. what kind of clusters are being made).\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SSoasDQSKXb"
   },
   "outputs": [],
   "source": [
    "# Clustering labels without output as feature\n",
    "# Load evaluation data\n",
    "scores = []\n",
    "for k in range(2,8):\n",
    "    kmns = KMEANSClustering(k=k)\n",
    "    kmns.fit(iris)\n",
    "    # Print clusters\n",
    "    kmns.print_clusters()\n",
    "    scores.append(kmns.silhouette)\n",
    "    print('-'*40)\n",
    "    \n",
    "plt.plot(range(2,8), scores)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "plt.ylim(ymin=0, ymax=1.1)\n",
    "plt.title(\"K-Means without output\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4SSoasDQSKXb"
   },
   "outputs": [],
   "source": [
    "# Clustering labels with output as feature\n",
    "# Load evaluation data\n",
    "scores = []\n",
    "for k in range(2,8):\n",
    "    kmns = KMEANSClustering(k=k)\n",
    "    kmns.fit(iris_w_output)\n",
    "    # Print clusters\n",
    "    kmns.print_clusters()\n",
    "    scores.append(kmns.silhouette)\n",
    "    print('-'*40)\n",
    "    \n",
    "plt.plot(range(2,8), scores)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Silhouette score\")\n",
    "plt.ylim(ymin=0, ymax=1.1)\n",
    "plt.title(\"K-Means with output\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare results and differences between using the output label and excluding the output label**<br>\n",
    "Much like the HAC problems, the KMeans classification did much better when provided the output label. It did much better when `k=3`, the original number of output classes, and stayed pretty  constant otherwise. If not given the output classes, the algorithm definately favored smaller values of `k` with one notable exception: `k=6`. I'm not sure what to make of it; I would guess that the algorithm found something that really helped split each of the groups in half, or something similar to that. I find it very strange that there was a peak at exactly 2 times the normal output class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 2.2.2 (5%) Clustering the Iris Classification problem: K-Means\n",
    "\n",
    "Requirements:\n",
    "- Use the output label as an input feature\n",
    "- Run K-Means 5 times with k=4, each time with different initial random centroids and discuss any variations in the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#K-Means 5 times\n",
    "for i in range(5):\n",
    "    print(f\"ITERATION {i+1}\")\n",
    "    kmns = KMEANSClustering(k=4)\n",
    "    kmns.fit(X)\n",
    "\n",
    "    # Print clusters\n",
    "    kmns.print_clusters()\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discuss any variations in the results**<br>\n",
    "The silhouette scores did not vary much. I found this interesting, as I figured the random choice would significantly impact the variation. However, it seems like the data is sufficiently separated that when I run the kmeans clustering without any limit of iterations, it usually arrives at the same result every time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBBmeNQ7jvcQ",
    "tags": []
   },
   "source": [
    "## 3.1 (12.5%) Run the SK versions of HAC (both single and complete link) on iris including the output label and compare your results with those above.\n",
    "Use the silhouette score for this iris problem(k = 2-7).  You may write your own code to do silhouette (optional extra credit) or you can use sklearn.metrics.silhouette_score. Please state if you coded your own silhouette score function to receive the extra credit points (described below). Discuss how helpful Silhouette appeared to be for selecting which clustering is best. You do not need to supply full Silhouette graphs, but you could if you wanted to.\n",
    "\n",
    "Requirements\n",
    "- Use the Sillhouette score for this iris problem (k= 2-7) \n",
    "- Use at least one other scoring function from [sklearn.metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) and compare the results. State which metric was used. \n",
    "- Possible sklean metrics include (* metrics require ground truth labels):\n",
    "    - adjusted_mutual_info_score*\n",
    "    - adjusted_rand_score*\n",
    "    - homogeneity_score*\n",
    "    - completeness_score*\n",
    "    - fowlkes_mallows_score*\n",
    "    - calinski_harabasz_score\n",
    "    - davies_bouldin_score\n",
    "- Experiment using different hyper-parameters. Discuss Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OFQv70W2VyqJ"
   },
   "outputs": [],
   "source": [
    "# Load sklearn\n",
    "import itertools as it\n",
    "from sklearn.metrics import silhouette_score, completeness_score, adjusted_mutual_info_score\n",
    "metrics = ['euclidean', 'manhattan', 'cosine', 'l1', 'l2']\n",
    "linkages = ['ward', 'complete', 'average', 'single']\n",
    "\n",
    "args_list = [{'metric': metric,  'linkage': linkage} for metric, linkage in it.product(metrics, linkages) ]\n",
    "# args_strings = [' | '.join([f\"{arg}={val}\" for arg, val in args.items()]) for arg in args_list]\n",
    "\n",
    "int_labels = np.unique(labels, return_inverse=True)[1]\n",
    "\n",
    "silhouette= []\n",
    "completeness = []\n",
    "adjusted_mututal_info = []\n",
    "remove_args = []\n",
    "for i, args in enumerate(args_list):\n",
    "    if args['linkage'] == 'ward' and args['metric'] != 'euclidean':\n",
    "        remove_args.append(i)\n",
    "        continue\n",
    "    sil_i = []\n",
    "    comp_i = []\n",
    "    adj_i = []\n",
    "    for k in range(2,8):\n",
    "        args['n_clusters'] = k\n",
    "        hac = AgglomerativeClustering(**args)\n",
    "        predicted_labels = hac.fit_predict(iris_w_output)\n",
    "\n",
    "        sil_i.append(silhouette_score(iris_w_output, predicted_labels, metric=args['metric']))\n",
    "        comp_i.append(completeness_score(int_labels, predicted_labels))\n",
    "        adj_i.append(adjusted_mutual_info_score(int_labels, predicted_labels))\n",
    "        del args['n_clusters']\n",
    "    \n",
    "    silhouette.append(tuple(sil_i))\n",
    "    completeness.append(tuple(comp_i))\n",
    "    adjusted_mututal_info.append(tuple(adj_i))\n",
    "\n",
    "args_list = [arg for i, arg in enumerate(args_list) if i not in remove_args]\n",
    "args_strings = [str(arg) for arg in args_list]\n",
    "for score_name, scores in zip((\"Silhouette\", \"Completeness\", \"Adjusted Mutual Info\"), (silhouette, completeness, adjusted_mututal_info)):\n",
    "    plt.figure(figsize=(30,20))\n",
    "    for s_i in scores:\n",
    "        plt.plot(range(2,8), s_i, label=True, linewidth=4)\n",
    "    \n",
    "    plt.legend(args_strings, fontsize=20,loc=\"lower center\", ncol=2)\n",
    "    plt.title(f\"{score_name} score\", fontweight='bold')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylim(ymin=0, ymax=1.1)\n",
    "    plt.xlim(xmin=2, xmax=7)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqSFAXwlk3Ms"
   },
   "source": [
    "**Record impressions**<br>\n",
    "The combination of hyperparameters that consistently performed among the best was `metric=cosine, linkage=single`. All other top-level combinations always seemed to fail in at least one other respect. For instance, argument pairs such as `euclidean, ward` and `l1, complete` did very well with the completeness score and adjusted mutual info score, but did worse for the silhouette score. This made me wonder how one would select  the best scoring metric: there seems to be a lot of variation! However, the one nice thing is that all of the hyperparameter combinations made the scores follow a similar pattern, so as long as you stuck to one, you would be able to appropriately compare scores at least.\n",
    "<br><br>\n",
    "What I found bizzare is that the `cosine` distance metrics did so well. Not sure how this makes a difference, but it is definately something to look into.<br><br>\n",
    "Also, sorry that the colors looped; I couldn't figure out how to get matplotlib to stop doing that in the time I had. :/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBBmeNQ7jvcQ",
    "tags": []
   },
   "source": [
    "## 3.2 (12.5%) Run the SK version of k-means on iris including the output label and compare your results with those above. \n",
    "\n",
    "Use the silhouette score for this iris problem(k = 2-7). You may write your own code to do silhouette (optional extra credit) or you can use sklearn.metrics.silhouette_score. Please state if you coded your own silhouette score function to receive the extra credit points (described below). Discuss how helpful Silhouette appeared to be for selecting which clustering is best. You do not need to supply full Silhouette graphs, but you could if you wanted to.\n",
    "\n",
    "Requirements\n",
    "- Use the Sillhouette score for this iris problem (k= 2-7) \n",
    "- Use at least one other scoring function form sklearn.metrics and compare the results. State which metric was used\n",
    "- Experiment different hyper-parameters. Discuss Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load sklearn\n",
    "inits = ['k-means++', 'random']\n",
    "n_inits = [5, 10, 20]\n",
    "max_iters = [100, 300, 600]\n",
    "algorithms = ['lloyd', 'elkan']\n",
    "\n",
    "args_list = [{'init': init, 'n_init': n_init, 'max_iter': max_iter, 'algorithm': algorithm} \n",
    "             for init, n_init, max_iter, algorithm in it.product(inits, n_inits, max_iters, algorithms)]\n",
    "# args_strings = [' | '.join([f\"{arg}={val}\" for arg, val in args.items()]) for arg in args_list]\n",
    "args_strings = [str(arg) for arg in args_list]\n",
    "\n",
    "int_labels = np.unique(labels, return_inverse=True)[1]\n",
    "\n",
    "silhouette= []\n",
    "completeness = []\n",
    "adjusted_mututal_info = []\n",
    "for args in args_list:\n",
    "    sil_i = []\n",
    "    comp_i = []\n",
    "    adj_i = []\n",
    "    for k in range(2,8):\n",
    "        args['n_clusters'] = k\n",
    "        kmeans = KMeans(**args)\n",
    "        predicted_labels = kmeans.fit_predict(iris_w_output)\n",
    "\n",
    "        sil_i.append(silhouette_score(iris_w_output, predicted_labels))\n",
    "        comp_i.append(completeness_score(int_labels, predicted_labels))\n",
    "        adj_i.append(adjusted_mutual_info_score(int_labels, predicted_labels))\n",
    "        del args['n_clusters']\n",
    "    \n",
    "    silhouette.append(tuple(sil_i))\n",
    "    completeness.append(tuple(comp_i))\n",
    "    adjusted_mututal_info.append(tuple(adj_i))\n",
    "\n",
    "for score_name, scores in zip((\"Silhouette\", \"Completeness\", \"Adjusted Mutual Info\"), (silhouette, completeness, adjusted_mututal_info)):\n",
    "    plt.figure(figsize=(30,20))\n",
    "    for s_i in scores:\n",
    "        plt.plot(range(2,8), s_i, label=True, linewidth=4)\n",
    "    \n",
    "    plt.legend(args_strings, fontsize=15, loc=\"lower center\", ncol=3)\n",
    "    plt.title(f\"{score_name} score\", fontweight='bold')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylim(ymin=0, ymax=1.1)\n",
    "    plt.xlim(xmin=2, xmax=7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqSFAXwlk3Ms"
   },
   "source": [
    "**Record impressions**<br><br>\n",
    "Unlike the HAC, All of the different hyperparameters seemed to perform fairly similarly. There was a peak around `k=3` (though not for `silhouette` strangely enough; still scored highly), then decreased. This follows a similar pattern to that seen in section 2.2. This makes sense, as the output label was included. When I didn't include the labels (below), The pattern also followed the same as above, sitting at a max early on and tapering off. Interestingly though, the Adjusted Mutual info score did show a peak around 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load sklearn\n",
    "inits = ['k-means++', 'random']\n",
    "n_inits = [5, 10, 20]\n",
    "max_iters = [100, 300, 600]\n",
    "algorithms = ['lloyd', 'elkan']\n",
    "\n",
    "args_list = [{'init': init, 'n_init': n_init, 'max_iter': max_iter, 'algorithm': algorithm} \n",
    "             for init, n_init, max_iter, algorithm in it.product(inits, n_inits, max_iters, algorithms)]\n",
    "# args_strings = [' | '.join([f\"{arg}={val}\" for arg, val in args.items()]) for arg in args_list]\n",
    "args_strings = [str(arg) for arg in args_list]\n",
    "\n",
    "int_labels = np.unique(labels, return_inverse=True)[1]\n",
    "\n",
    "silhouette= []\n",
    "completeness = []\n",
    "adjusted_mututal_info = []\n",
    "for args in args_list:\n",
    "    sil_i = []\n",
    "    comp_i = []\n",
    "    adj_i = []\n",
    "    for k in range(2,8):\n",
    "        args['n_clusters'] = k\n",
    "        kmeans = KMeans(**args)\n",
    "        predicted_labels = kmeans.fit_predict(iris)\n",
    "\n",
    "        sil_i.append(silhouette_score(iris, predicted_labels))\n",
    "        comp_i.append(completeness_score(int_labels, predicted_labels))\n",
    "        adj_i.append(adjusted_mutual_info_score(int_labels, predicted_labels))\n",
    "        del args['n_clusters']\n",
    "    \n",
    "    silhouette.append(tuple(sil_i))\n",
    "    completeness.append(tuple(comp_i))\n",
    "    adjusted_mututal_info.append(tuple(adj_i))\n",
    "\n",
    "for score_name, scores in zip((\"Silhouette\", \"Completeness\", \"Adjusted Mutual Info\"), (silhouette, completeness, adjusted_mututal_info)):\n",
    "    plt.figure(figsize=(30,20))\n",
    "    for s_i in scores:\n",
    "        plt.plot(range(2,8), s_i, label=True, linewidth=4)\n",
    "    \n",
    "    plt.legend(args_strings, fontsize=15, loc=\"lower center\", ncol=3)\n",
    "    plt.title(f\"{score_name} score\", fontweight='bold')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylim(ymin=0, ymax=1.1)\n",
    "    plt.xlim(xmin=2, xmax=7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy function Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab 1 - perceptron",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
